"""
SCARA ë¡œë´‡ ë°ì´í„°ë¡œ AI ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨
processed_scara_data_*.csv íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.
"""

import os
import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings

warnings.filterwarnings('ignore')

# ì•ˆì „í•œ import
try:
    from predictive_model import IoTPredictiveMaintenanceModel
    MODEL_AVAILABLE = True
except ImportError:
    print("âš ï¸  predictive_model.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    MODEL_AVAILABLE = False

try:
    import tensorflow as tf
    print(f"âœ… TensorFlow {tf.__version__} ë¡œë“œë¨")
    TF_AVAILABLE = True
except ImportError:
    print("âŒ TensorFlowë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. pip install tensorflow")
    TF_AVAILABLE = False


def load_scara_data(csv_file_path):
    """SCARA ë¡œë´‡ ë°ì´í„° ë¡œë“œ ë° ê²€ì¦"""
    
    print(f"ğŸ“ ë°ì´í„° ë¡œë“œ: {csv_file_path}")
    
    if not os.path.exists(csv_file_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_file_path}")
        return None
    
    try:
        # CSV íŒŒì¼ ë¡œë“œ
        df = pd.read_csv(csv_file_path)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(df):,}í–‰ x {len(df.columns)}ì—´")
        
        # ê¸°ë³¸ ì •ë³´ ì¶œë ¥
        file_size = os.path.getsize(csv_file_path) / (1024*1024)  # MB
        print(f"ğŸ“ íŒŒì¼ í¬ê¸°: {file_size:.1f} MB")
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            time_range = df['timestamp'].max() - df['timestamp'].min()
            print(f"â° ì‹œê°„ ë²”ìœ„: {time_range}")
            print(f"   ì‹œì‘: {df['timestamp'].min()}")
            print(f"   ì¢…ë£Œ: {df['timestamp'].max()}")
        
        # ë°ì´í„° í’ˆì§ˆ í™•ì¸
        print(f"\nğŸ“Š ë°ì´í„° í’ˆì§ˆ ì²´í¬:")
        
        # ê²°ì¸¡ê°’ í™•ì¸
        missing_data = df.isnull().sum()
        missing_cols = missing_data[missing_data > 0]
        
        if len(missing_cols) > 0:
            print(f"   âš ï¸  ê²°ì¸¡ê°’: {len(missing_cols)}ê°œ ì»¬ëŸ¼")
            for col, count in missing_cols.head(5).items():
                print(f"     - {col}: {count}ê°œ ({count/len(df)*100:.1f}%)")
        else:
            print(f"   âœ… ê²°ì¸¡ê°’ ì—†ìŒ")
        
        # ì£¼ìš” í†µê³„
        if 'health_score' in df.columns:
            print(f"   ê±´ê°•ë„: í‰ê·  {df['health_score'].mean():.1f}% (ë²”ìœ„: {df['health_score'].min():.1f}% ~ {df['health_score'].max():.1f}%)")
        
        if 'anomaly_score' in df.columns:
            print(f"   ì´ìƒì ìˆ˜: í‰ê·  {df['anomaly_score'].mean():.3f} (ë²”ìœ„: {df['anomaly_score'].min():.3f} ~ {df['anomaly_score'].max():.3f})")
        
        if 'status' in df.columns:
            status_counts = df['status'].value_counts()
            print(f"   ìƒíƒœ ë¶„í¬: {dict(status_counts)}")
        
        return df
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def analyze_scara_features(df):
    """SCARA ë¡œë´‡ íŠ¹ì„± ë¶„ì„"""
    
    print(f"\nğŸ” SCARA ë¡œë´‡ íŠ¹ì„± ë¶„ì„")
    print("="*50)
    
    # íŠ¹ì„± ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
    feature_categories = {
        'ì‹œê°„': [col for col in df.columns if col in ['timestamp', 'hour', 'day_of_week', 'minute']],
        'ê´€ì ˆ ìœ„ì¹˜': [col for col in df.columns if 'actual_pos' in col and 'joint' in col],
        'ìœ„ì¹˜ ëª…ë ¹': [col for col in df.columns if 'cmd_pos' in col and 'joint' in col],
        'ìœ„ì¹˜ ì˜¤ì°¨': [col for col in df.columns if 'pos_error' in col and 'joint' in col],
        'í† í¬ ëª…ë ¹': [col for col in df.columns if 'torque_cmd' in col and 'joint' in col],
        'í† í¬ í”¼ë“œë°±': [col for col in df.columns if 'torque_feedback' in col and 'joint' in col],
        'Cartesian': [col for col in df.columns if 'cartesian' in col],
        'SCARA ì¢Œí‘œ': [col for col in df.columns if 'scara' in col],
        'ì—”ì§€ë‹ˆì–´ë§': [col for col in df.columns if any(x in col for x in ['total_', 'mean_', 'max_', '_ma_', '_std_', '_change'])],
        'íƒ€ê²Ÿ ë³€ìˆ˜': [col for col in df.columns if col in ['health_score', 'anomaly_score', 'status', 'device_id']]
    }
    
    print(f"ğŸ“‹ íŠ¹ì„± ì¹´í…Œê³ ë¦¬:")
    total_features = 0
    for category, features in feature_categories.items():
        if features:
            print(f"   {category}: {len(features)}ê°œ")
            total_features += len(features)
            # ìƒ˜í”Œ íŠ¹ì„± ì¶œë ¥
            if len(features) <= 5:
                for feature in features:
                    print(f"     - {feature}")
            else:
                for feature in features[:3]:
                    print(f"     - {feature}")
                print(f"     ... ë° {len(features)-3}ê°œ ì¶”ê°€")
    
    print(f"\nğŸ“Š ì´ íŠ¹ì„± ìˆ˜: {total_features}ê°œ")
    
    # ìƒê´€ê´€ê³„ê°€ ë†’ì€ ì£¼ìš” íŠ¹ì„±ë“¤ ì°¾ê¸°
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 10:  # ë„ˆë¬´ ë§ìœ¼ë©´ ìƒ˜í”Œë§
        sample_cols = np.random.choice(numeric_cols, 10, replace=False)
        corr_matrix = df[sample_cols].corr()
        
        print(f"\nğŸ”— ì£¼ìš” íŠ¹ì„± ìƒê´€ê´€ê³„ (ìƒ˜í”Œ 10ê°œ):")
        # ë†’ì€ ìƒê´€ê´€ê³„ ì°¾ê¸°
        high_corr_pairs = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.7:  # ë†’ì€ ìƒê´€ê´€ê³„
                    high_corr_pairs.append((
                        corr_matrix.columns[i], 
                        corr_matrix.columns[j], 
                        corr_val
                    ))
        
        if high_corr_pairs:
            for col1, col2, corr_val in high_corr_pairs[:5]:
                print(f"   {col1} â†” {col2}: {corr_val:.3f}")
        else:
            print(f"   ë†’ì€ ìƒê´€ê´€ê³„ (>0.7) ì—†ìŒ")
    
    return feature_categories


def prepare_model_data(df):
    """ëª¨ë¸ í›ˆë ¨ìš© ë°ì´í„° ì¤€ë¹„"""
    
    print(f"\nğŸ”§ ëª¨ë¸ í›ˆë ¨ìš© ë°ì´í„° ì¤€ë¹„")
    print("="*40)
    
    # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸
    required_cols = ['timestamp', 'health_score', 'anomaly_score', 'status']
    missing_cols = [col for col in required_cols if col not in df.columns]
    
    if missing_cols:
        print(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
        return None
    
    # ë””ë°”ì´ìŠ¤ ID í™•ì¸/ìƒì„±
    if 'device_id' not in df.columns:
        df['device_id'] = 'SCARA_ROBOT_001'
        print(f"ğŸ“ device_id ì»¬ëŸ¼ ìƒì„±: SCARA_ROBOT_001")
    
    # íƒ€ê²Ÿ ë³€ìˆ˜ ì¤€ë¹„
    print(f"ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬:")
    
    # ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ maintenance_needed ìƒì„±
    if 'maintenance_needed' not in df.columns:
        # ê±´ê°•ë„ 70% ë¯¸ë§Œ ë˜ëŠ” ì´ìƒì ìˆ˜ 0.5 ì´ìƒì´ë©´ ìœ ì§€ë³´ìˆ˜ í•„ìš”
        df['maintenance_needed'] = (
            (df['health_score'] < 70) | (df['anomaly_score'] > 0.5)
        ).astype(int)
    
    maintenance_dist = df['maintenance_needed'].value_counts()
    print(f"   ìœ ì§€ë³´ìˆ˜ í•„ìš”: {maintenance_dist}")
    print(f"   ë¹„ìœ¨: {maintenance_dist[1] / len(df) * 100:.1f}% í•„ìš”")
    
    # íŠ¹ì„± ì„ íƒ (ëª¨ë¸ ì„±ëŠ¥ì„ ìœ„í•´)
    feature_cols = []
    
    # ì£¼ìš” ì„¼ì„œ ë°ì´í„°
    sensor_cols = [col for col in df.columns if any(keyword in col for keyword in 
                   ['actual_pos', 'pos_error', 'torque_cmd', 'cartesian'])]
    feature_cols.extend(sensor_cols)
    
    # ì—”ì§€ë‹ˆì–´ë§ íŠ¹ì„± (ì£¼ìš”í•œ ê²ƒë“¤ë§Œ)
    engineering_cols = [col for col in df.columns if any(keyword in col for keyword in 
                       ['total_', 'mean_', 'max_', '_imbalance', '_std_5', '_ma_5'])]
    feature_cols.extend(engineering_cols)
    
    # ì‹œê°„ íŠ¹ì„±
    time_cols = [col for col in df.columns if col in ['hour', 'day_of_week', 'minute']]
    feature_cols.extend(time_cols)
    
    # ì¤‘ë³µ ì œê±°
    feature_cols = list(set(feature_cols))
    feature_cols = [col for col in feature_cols if col in df.columns]
    
    print(f"ğŸ“Š ì„ íƒëœ íŠ¹ì„±: {len(feature_cols)}ê°œ")
    print(f"   ì„¼ì„œ ë°ì´í„°: {len(sensor_cols)}ê°œ")
    print(f"   ì—”ì§€ë‹ˆì–´ë§: {len(engineering_cols)}ê°œ")
    print(f"   ì‹œê°„ íŠ¹ì„±: {len(time_cols)}ê°œ")
    
    # ë°ì´í„° ì •ë¦¬
    model_df = df[['timestamp', 'device_id', 'health_score', 'anomaly_score', 
                   'status', 'maintenance_needed'] + feature_cols].copy()
    
    # ê²°ì¸¡ê°’ ì²˜ë¦¬
    numeric_cols = model_df.select_dtypes(include=[np.number]).columns
    model_df[numeric_cols] = model_df[numeric_cols].fillna(method='ffill').fillna(0)
    
    print(f"âœ… ëª¨ë¸ìš© ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(model_df)}í–‰ x {len(model_df.columns)}ì—´")
    
    return model_df


def train_scara_model(model_df):
    """SCARA ë¡œë´‡ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨"""
    
    if not MODEL_AVAILABLE or not TF_AVAILABLE:
        print("âŒ ëª¨ë¸ í›ˆë ¨ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    print(f"\nğŸ¤– SCARA ë¡œë´‡ AI ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
    print("="*50)
    
    try:
        # ëª¨ë¸ ì´ˆê¸°í™” (SCARA ë¡œë´‡ì— ìµœì í™”ëœ ì„¤ì •)
        model = IoTPredictiveMaintenanceModel(
            sequence_length=30,  # 5ë¶„ ì‹œí€€ìŠ¤ (30 x 10ì´ˆ)
            prediction_horizon=18  # 3ë¶„ í›„ ì˜ˆì¸¡ (18 x 10ì´ˆ)
        )
        
        print(f"ğŸ—ï¸  ëª¨ë¸ êµ¬ì„±:")
        print(f"   ì‹œí€€ìŠ¤ ê¸¸ì´: {model.sequence_length} (5ë¶„)")
        print(f"   ì˜ˆì¸¡ ê¸°ê°„: {model.prediction_horizon} (3ë¶„ í›„)")
        
        # í›ˆë ¨ ì‹¤í–‰
        print(f"\nğŸ‹ï¸  ëª¨ë¸ í›ˆë ¨ ì¤‘...")
        print(f"   ë°ì´í„°: {len(model_df):,}ê°œ ì‹œì ")
        print(f"   íŠ¹ì„±: {len(model_df.columns)}ê°œ")
        
        history = model.train(
            model_df,
            epochs=50,  # SCARA ë°ì´í„°ì— ì í•©í•œ ì—í¬í¬
            batch_size=32,
            validation_split=0.2
        )
        
        print(f"âœ… í›ˆë ¨ ì™„ë£Œ!")
        
        # ëª¨ë¸ ì €ì¥
        model_name = f"scara_robot_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        model.save_model(model_name)
        print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥: {model_name}")
        
        # í›ˆë ¨ íˆìŠ¤í† ë¦¬ ì‹œê°í™”
        if hasattr(history, 'history'):
            plot_training_history(history, model_name)
        
        # ìƒ˜í”Œ ì˜ˆì¸¡ ìˆ˜í–‰
        sample_prediction(model, model_df)
        
        return model, model_name
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None, None


def plot_training_history(history, model_name):
    """í›ˆë ¨ íˆìŠ¤í† ë¦¬ ì‹œê°í™”"""
    
    try:
        print(f"\nğŸ“Š í›ˆë ¨ ê²°ê³¼ ì‹œê°í™”...")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'SCARA ë¡œë´‡ ëª¨ë¸ í›ˆë ¨ ê²°ê³¼ - {model_name}', fontsize=16, fontweight='bold')
        
        # 1. ì†ì‹¤ ê·¸ë˜í”„
        ax1 = axes[0, 0]
        ax1.plot(history.history['loss'], label='Training Loss', color='blue', linewidth=2)
        ax1.plot(history.history['val_loss'], label='Validation Loss', color='red', linewidth=2)
        ax1.set_title('ëª¨ë¸ ì†ì‹¤ (Loss)', fontweight='bold')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. ì •í™•ë„ ê·¸ë˜í”„
        ax2 = axes[0, 1]
        if 'accuracy' in history.history:
            ax2.plot(history.history['accuracy'], label='Training Accuracy', color='blue', linewidth=2)
            ax2.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red', linewidth=2)
            ax2.set_title('ëª¨ë¸ ì •í™•ë„ (Accuracy)', fontweight='bold')
            ax2.set_xlabel('Epoch')
            ax2.set_ylabel('Accuracy')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
        else:
            ax2.text(0.5, 0.5, 'Accuracy ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=ax2.transAxes)
            ax2.set_title('ëª¨ë¸ ì •í™•ë„', fontweight='bold')
        
        # 3. í•™ìŠµë¥  ë³€í™” (ìˆëŠ” ê²½ìš°)
        ax3 = axes[1, 0]
        if 'lr' in history.history:
            ax3.plot(history.history['lr'], color='green', linewidth=2)
            ax3.set_title('í•™ìŠµë¥  ë³€í™”', fontweight='bold')
            ax3.set_xlabel('Epoch')
            ax3.set_ylabel('Learning Rate')
            ax3.set_yscale('log')
            ax3.grid(True, alpha=0.3)
        else:
            ax3.text(0.5, 0.5, 'í•™ìŠµë¥  ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=ax3.transAxes)
            ax3.set_title('í•™ìŠµë¥  ë³€í™”', fontweight='bold')
        
        # 4. í›ˆë ¨ ìš”ì•½
        ax4 = axes[1, 1]
        ax4.axis('off')
        
        # ìµœì¢… ì„±ëŠ¥ ë©”íŠ¸ë¦­
        final_loss = history.history['val_loss'][-1] if 'val_loss' in history.history else 'N/A'
        final_acc = history.history['val_accuracy'][-1] if 'val_accuracy' in history.history else 'N/A'
        total_epochs = len(history.history['loss'])
        
        summary_text = f"""
í›ˆë ¨ ìš”ì•½:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì´ ì—í¬í¬: {total_epochs}
ìµœì¢… ê²€ì¦ ì†ì‹¤: {final_loss:.4f if final_loss != 'N/A' else 'N/A'}
ìµœì¢… ê²€ì¦ ì •í™•ë„: {final_acc:.4f if final_acc != 'N/A' else 'N/A'}

ëª¨ë¸ êµ¬ì„±:
â€¢ ì•„í‚¤í…ì²˜: LSTM + Dense
â€¢ ì‹œí€€ìŠ¤ ê¸¸ì´: 30 (5ë¶„)
â€¢ ì˜ˆì¸¡ ê¸°ê°„: 18 (3ë¶„ í›„)
â€¢ ë°°ì¹˜ í¬ê¸°: 32

ë°ì´í„°ì…‹:
â€¢ SCARA ë¡œë´‡ ì„¼ì„œ ë°ì´í„°
â€¢ 4ê°œ ê´€ì ˆ (J1, J2, J3, J6)
â€¢ ìœ„ì¹˜, í† í¬, ì˜¤ì°¨ ì •ë³´
        """
        
        ax4.text(0.05, 0.95, summary_text, transform=ax4.transAxes, fontsize=11,
                verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray", alpha=0.8))
        
        plt.tight_layout()
        
        # ì €ì¥
        plot_filename = f"{model_name}_training_history.png"
        plt.savefig(plot_filename, dpi=150, bbox_inches='tight', facecolor='white')
        print(f"ğŸ’¾ í›ˆë ¨ ê·¸ë˜í”„ ì €ì¥: {plot_filename}")
        
        plt.show()
        
    except Exception as e:
        print(f"âš ï¸  ì‹œê°í™” ì˜¤ë¥˜: {e}")


def sample_prediction(model, model_df):
    """ìƒ˜í”Œ ì˜ˆì¸¡ ìˆ˜í–‰"""
    
    try:
        print(f"\nğŸ”® ìƒ˜í”Œ ì˜ˆì¸¡ ìˆ˜í–‰...")
        
        # ìµœê·¼ ë°ì´í„°ë¡œ ì˜ˆì¸¡
        device_id = model_df['device_id'].iloc[0]
        recent_data = model_df.tail(500)  # ìµœê·¼ 500ê°œ ì‹œì 
        
        prediction = model.predict(recent_data, device_id)
        
        print(f"ğŸ“± SCARA ë¡œë´‡ ì˜ˆì¸¡ ê²°ê³¼:")
        print(f"   ë””ë°”ì´ìŠ¤: {prediction['device_id']}")
        print(f"   ìœ ì§€ë³´ìˆ˜ í™•ë¥ : {prediction['maintenance_probability']:.1%}")
        print(f"   ìœ ì§€ë³´ìˆ˜ í•„ìš”: {'âœ… ì˜ˆ' if prediction['maintenance_needed'] else 'âŒ ì•„ë‹ˆì˜¤'}")
        print(f"   ìœ„í—˜ ìˆ˜ì¤€: {prediction['risk_level']}")
        print(f"   ì˜ˆì¸¡ ì‹œì : {prediction.get('timestamp', 'N/A')}")
        
        # ìœ„í—˜ ìˆ˜ì¤€ë³„ ê¶Œì¥ì‚¬í•­
        risk_recommendations = {
            'low': "ì •ìƒ ìš´ì˜ ìƒíƒœì…ë‹ˆë‹¤. ì •ê¸° ì ê²€ë§Œ ìˆ˜í–‰í•˜ì„¸ìš”.",
            'medium': "ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì„¼ì„œ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ì˜ˆë°© ì •ë¹„ë¥¼ ê³„íší•˜ì„¸ìš”.",
            'high': "ì¦‰ì‹œ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤. ìš´ì˜ì„ ì¤‘ë‹¨í•˜ê³  ì „ë¬¸ê°€ì˜ ì§„ë‹¨ì„ ë°›ìœ¼ì„¸ìš”."
        }
        
        recommendation = risk_recommendations.get(prediction['risk_level'], "ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        print(f"   ğŸ’¡ ê¶Œì¥ì‚¬í•­: {recommendation}")
        
        return prediction
        
    except Exception as e:
        print(f"âš ï¸  ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        return None


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸ¤– SCARA ë¡œë´‡ AI ëª¨ë¸ í›ˆë ¨ ì‹œìŠ¤í…œ")
    print("="*60)
    
    # 1. CSV íŒŒì¼ ì°¾ê¸°
    csv_files = [f for f in os.listdir('.') if f.startswith('processed_scara_data_') and f.endswith('.csv')]
    
    if not csv_files:
        print("âŒ processed_scara_data_*.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € fixed_xml_data_processor.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì„¸ìš”.")
        return
    
    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
    latest_file = max(csv_files, key=lambda x: os.path.getmtime(x))
    print(f"ğŸ“ ìµœì‹  ë°ì´í„° íŒŒì¼: {latest_file}")
    
    # 2. ë°ì´í„° ë¡œë“œ
    df = load_scara_data(latest_file)
    if df is None:
        return
    
    # 3. íŠ¹ì„± ë¶„ì„
    feature_categories = analyze_scara_features(df)
    
    # 4. ëª¨ë¸ ë°ì´í„° ì¤€ë¹„
    model_df = prepare_model_data(df)
    if model_df is None:
        return
    
    # 5. ì‚¬ìš©ì í™•ì¸
    print(f"\nğŸš€ ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
    print(f"   ë°ì´í„°: {len(model_df):,}ê°œ ì‹œì ")
    print(f"   íŠ¹ì„±: {len(model_df.columns)}ê°œ")
    print(f"   ì˜ˆìƒ ì‹œê°„: 5-15ë¶„")
    
    response = input(f"\ní›ˆë ¨ ì‹œì‘? (y/N): ")
    if response.lower() != 'y':
        print("í›ˆë ¨ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return
    
    # 6. ëª¨ë¸ í›ˆë ¨
    model, model_name = train_scara_model(model_df)
    
    if model and model_name:
        print(f"\nğŸ‰ SCARA ë¡œë´‡ AI ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼ë“¤:")
        print(f"   ğŸ¤– ëª¨ë¸: {model_name}.h5")
        print(f"   ğŸ”§ ìŠ¤ì¼€ì¼ëŸ¬: {model_name}_scaler.pkl")
        print(f"   ğŸ“„ ë©”íƒ€ë°ì´í„°: {model_name}_metadata.json")
        print(f"   ğŸ“Š í›ˆë ¨ ê·¸ë˜í”„: {model_name}_training_history.png")
        
        print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
        print(f"1. ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œì— ëª¨ë¸ í†µí•©")
        print(f"2. ëŒ€ì‹œë³´ë“œì—ì„œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")
        print(f"3. ì•Œë¦¼ ì‹œìŠ¤í…œ ì„¤ì •")
        
        return model_name
    else:
        print(f"\nâŒ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨")
        return None


if __name__ == "__main__":
    model_name = main()
